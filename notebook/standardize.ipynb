{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0490837",
   "metadata": {},
   "source": [
    "# Standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa6350",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Automatically detect the repo root (parent of notebook folder)\n",
    "repo_root = Path().resolve().parent  # if notebook is in 'notebooks/' folder\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from config.config import get_environment\n",
    "\n",
    "from config.config import data_import_json, data_export_json, data_import_pandas, data_export_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54779f8a",
   "metadata": {},
   "source": [
    "## ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8429e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = get_environment(\n",
    "    env_path=\"../environments\",\n",
    "    env_name=\"env.json\"\n",
    ")\n",
    "\n",
    "# content_date = datetime.now().date() + timedelta(days=0)\n",
    "content_date = ENV['CONTENT_DATE']\n",
    "version = ENV['VERSION']\n",
    "\n",
    "website = ENV['SOURCE']['NAME']\n",
    "# website = ENV['TARGET'][\"1\"]['NAME']\n",
    "# website = ENV['TARGET'][\"2\"]['NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3bd03",
   "metadata": {},
   "source": [
    "### Dependencies columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da04f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base columns for Standardize\n",
    "base_columns = [\n",
    "    'scrape_date', # datetime.date in str # as is\n",
    "    'website', # str\n",
    "    'category', # str\n",
    "    'brand', # str\n",
    "    'item_id', # str\n",
    "    'item_name', # str\n",
    "    'item_variant', # str\n",
    "    'item_url', # str\n",
    "    'url_image', # str\n",
    "    'in_stock', # int bool (1/0)\n",
    "    'review_total', # int\n",
    "    'review_rating', # float\n",
    "    'currency', # str\n",
    "    'price', # float\n",
    "    'price_after_disc', # float\n",
    "    'price_disc', # float\n",
    "    'is_package', # int bool (1/0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbe8ae",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e19aa",
   "metadata": {},
   "source": [
    "### Standardize Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Sociolla columns based on base columns\n",
    "def standardize_sociolla(\n",
    "        df_input: pd.DataFrame,\n",
    "        base_columns: list[str]=base_columns\n",
    "    ):\n",
    "\n",
    "    # Handle variant_id list, convert each element to str then join by _\n",
    "    df_input['variant_id'] = df_input['variant_id'].apply(\n",
    "        lambda v: '_'.join(\n",
    "            [\n",
    "                re.sub(r'\\.0\\b', '', str(s)) for s in v\n",
    "            ]\n",
    "        ) if isinstance(v, list)\n",
    "        else v\n",
    "    )\n",
    "\n",
    "    # Convert int to str safely\n",
    "    convert_cols = ['id', 'variant_id']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str).str.replace(r'\\.0\\b', '', regex=True)\n",
    "\n",
    "    # Convert to str\n",
    "    convert_cols = ['brand']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str)\n",
    "\n",
    "    # Handle variant_name list, convert each element to str then join by ' '\n",
    "    df_input['variant_name'] = df_input['variant_name'].apply(\n",
    "        lambda v: ' '.join(\n",
    "            [\n",
    "                str(s) for s in v\n",
    "            ]\n",
    "        ) if isinstance(v, list)\n",
    "        else v\n",
    "    )\n",
    "\n",
    "    # Non-specify as ''\n",
    "    df_input['variant_name'] = df_input['variant_name'].fillna('').astype(str).replace('Non Specify', '')\n",
    "\n",
    "    # Assign webiste\n",
    "    df_input['website'] = website\n",
    "\n",
    "    # Generate item_id\n",
    "    df_input['item_id'] = df_input[['id', 'variant_id']].apply(tuple, axis=1).str.join('_')\n",
    "\n",
    "    # Generate item_name\n",
    "    df_input['item_name'] = df_input[['name', 'variant_name']].apply(tuple, axis=1).str.join(' ').str.strip()\n",
    "\n",
    "    # Generate item_variant\n",
    "    df_input['item_variant'] = np.where(\n",
    "        df_input['variant_name'] != '',\n",
    "        df_input['variant_name'],\n",
    "        None\n",
    "    )\n",
    "\n",
    "    # Generate item_url\n",
    "    df_input['item_url'] = df_input['url']\n",
    "\n",
    "    # Generate in_stock\n",
    "    df_input['in_stock'] = np.where(\n",
    "        df_input['stock'] > 0,\n",
    "        int(1),\n",
    "        int(0)\n",
    "    )\n",
    "\n",
    "    # Convert is_package to int\n",
    "    df_input['is_package'] = np.where(\n",
    "        df_input['is_package'],\n",
    "        int(1),\n",
    "        int(0)\n",
    "    )\n",
    "\n",
    "    # Fill empty review with 0\n",
    "    fillna_cols = ['review_total', 'review_rating']\n",
    "    for col in fillna_cols:\n",
    "        df_input[col] = df_input[col].fillna(0)\n",
    "\n",
    "    # Generate price_disc\n",
    "    df_input['price_disc'] = df_input['price'] - df_input['price_after_disc']\n",
    "\n",
    "    # Round float 2 decimals\n",
    "    round_cols = ['review_rating', 'price', 'price_after_disc', 'price_disc']\n",
    "    for col in round_cols:\n",
    "        df_input[col] = df_input[col].round(2)\n",
    "\n",
    "    # Handle Duplicated Items (Prio in_stock desc and stock desc)\n",
    "    df_input.sort_values(by=['in_stock', 'stock'], ascending=[False, False], inplace=True)\n",
    "    # Remove duplicated, keep first based on sorted prio\n",
    "    df_input = df_input[~df_input['item_id'].duplicated()].copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    df_input = df_input[base_columns].copy(deep=True)\n",
    "\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Guardian columns based on base columns\n",
    "def standardize_guardian(\n",
    "        df_input: pd.DataFrame,\n",
    "        base_columns: list[str]=base_columns\n",
    "    ):\n",
    "\n",
    "    # Convert int to str safely\n",
    "    convert_cols = ['id']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str).str.replace(r'\\.0\\b', '', regex=True)\n",
    "\n",
    "    # Convert to str\n",
    "    convert_cols = ['brand']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str)\n",
    "\n",
    "    # Assign webiste\n",
    "    df_input['website'] = website\n",
    "\n",
    "    # Generate item_id\n",
    "    df_input['item_id'] = df_input['id']\n",
    "\n",
    "    # Generate item_name\n",
    "    df_input['item_name'] = df_input['name']\n",
    "\n",
    "    # Generate item_variant\n",
    "    df_input['item_variant'] = df_input['variant_name']\n",
    "\n",
    "    # Generate item_url\n",
    "    df_input['item_url'] = df_input['url']\n",
    "\n",
    "    # Generate in_stock\n",
    "    df_input['in_stock'] = np.where(\n",
    "        df_input['stock'] > 0,\n",
    "        int(1),\n",
    "        int(0)\n",
    "    )\n",
    "\n",
    "    # Fill empty review with 0\n",
    "    fillna_cols = ['review_total', 'review_rating']\n",
    "    for col in fillna_cols:\n",
    "        df_input[col] = df_input[col].fillna(0)\n",
    "\n",
    "    # Round float 2 decimals\n",
    "    round_cols = ['review_rating', 'price', 'price_after_disc', 'price_disc']\n",
    "    for col in round_cols:\n",
    "        df_input[col] = df_input[col].round(2)\n",
    "\n",
    "    # Handle Duplicated Items (Prio in_stock desc and stock desc)\n",
    "    df_input.sort_values(by=['in_stock', 'stock'], ascending=[False, False], inplace=True)\n",
    "    # Remove duplicated, keep first based on sorted prio\n",
    "    df_input = df_input[~df_input['item_id'].duplicated()].copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    df_input = df_input[base_columns].copy(deep=True)\n",
    "\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Watsons columns based on base columns\n",
    "def standardize_watsons(\n",
    "        df_input: pd.DataFrame,\n",
    "        base_columns: list[str]=base_columns\n",
    "    ):\n",
    "\n",
    "    # Convert int to str safely\n",
    "    convert_cols = ['id']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str).str.replace(r'\\.0\\b', '', regex=True)\n",
    "\n",
    "    # Convert to str\n",
    "    convert_cols = ['brand']\n",
    "    for col in convert_cols:\n",
    "        df_input[col] = df_input[col].fillna('').astype(str)\n",
    "\n",
    "    # Assign webiste\n",
    "    df_input['website'] = website\n",
    "\n",
    "    # Generate item_id\n",
    "    df_input['item_id'] = df_input['id']\n",
    "\n",
    "    # Generate item_name\n",
    "    df_input['item_name'] = df_input['name']\n",
    "\n",
    "    # Generate item_variant\n",
    "    df_input['item_variant'] = df_input['variant_name']\n",
    "\n",
    "    # Generate item_url\n",
    "    df_input['item_url'] = df_input['url']\n",
    "\n",
    "    # Generate in_stock\n",
    "    df_input['in_stock'] = np.where(\n",
    "        ~df_input['stock'].isin(['outOfStock']),\n",
    "        int(1),\n",
    "        int(0)\n",
    "    )\n",
    "\n",
    "    # Fill empty review with 0\n",
    "    fillna_cols = ['review_total', 'review_rating']\n",
    "    for col in fillna_cols:\n",
    "        df_input[col] = df_input[col].fillna(0)\n",
    "\n",
    "    # Fill empty price_after_disc with price\n",
    "    df_input['price_after_disc'] = df_input['price_after_disc'].fillna(df_input['price'])\n",
    "\n",
    "    # Generate price_disc\n",
    "    df_input['price_disc'] = df_input['price'] - df_input['price_after_disc']\n",
    "\n",
    "    # Round float 2 decimals\n",
    "    round_cols = ['review_rating', 'price', 'price_after_disc', 'price_disc']\n",
    "    for col in round_cols:\n",
    "        df_input[col] = df_input[col].round(2)\n",
    "\n",
    "    # Handle Duplicated Items (Prio in_stock desc and stock asc (inStock -> lowStock -> outOfStock))\n",
    "    df_input.sort_values(by=['in_stock', 'stock'], ascending=[False, True], inplace=True)\n",
    "    # Remove duplicated, keep first based on sorted prio\n",
    "    df_input = df_input[~df_input['item_id'].duplicated()].copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    df_input = df_input[base_columns].copy(deep=True)\n",
    "\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aefa6b",
   "metadata": {},
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64af09c",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e721e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = data_import_pandas(\n",
    "    website=website,\n",
    "    folder_name=f'parser/{website}',\n",
    "    version=version,\n",
    "    content_date=content_date, # \"0000-00-00\"\n",
    "    additional_info=\"parsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514b723",
   "metadata": {},
   "source": [
    "### Execute Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if website in ['sociolla']:\n",
    "    df_std = standardize_sociolla(\n",
    "        df_input=df_input,\n",
    "        base_columns=base_columns\n",
    "    )\n",
    "\n",
    "elif website in ['guardian']:\n",
    "    df_std = standardize_guardian(\n",
    "        df_input=df_input,\n",
    "        base_columns=base_columns\n",
    "    )\n",
    "\n",
    "elif website in ['watsons']:\n",
    "    df_std = standardize_watsons(\n",
    "        df_input=df_input,\n",
    "        base_columns=base_columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e9bdb",
   "metadata": {},
   "source": [
    "## Output per Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export_pandas(\n",
    "    df_output=df_std,\n",
    "    website=website,\n",
    "    folder_name=f'standardized/{website}',\n",
    "    version=version,\n",
    "    content_date=content_date, # \"0000-00-00\"\n",
    "    additional_info=\"standardized\",\n",
    "    incl_excel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360a841",
   "metadata": {},
   "source": [
    "## Merge across websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c95267",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_all = data_import_pandas(\n",
    "        website=\"all\",\n",
    "        folder_name='standardized/all',\n",
    "        version=version,\n",
    "        content_date=content_date, # \"0000-00-00\"\n",
    "        additional_info=\"standardized\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    df_all = pd.DataFrame()\n",
    "    df_all['website'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ac6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove current website from the exported data\n",
    "df_all = df_all[df_all['website'] != website].copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "# Merge current website\n",
    "df_all = pd.concat([\n",
    "    df_all,\n",
    "    df_std\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c60061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export merged across websites\n",
    "\n",
    "data_export_pandas(\n",
    "    df_output=df_all,\n",
    "    website=\"all\",\n",
    "    folder_name='standardized/all',\n",
    "    version=version,\n",
    "    content_date=content_date, # \"0000-00-00\"\n",
    "    additional_info=\"standardized\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
