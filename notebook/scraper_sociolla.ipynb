{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf8ea87",
   "metadata": {},
   "source": [
    "# Sociolla Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf486fe",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Automatically detect the repo root (parent of notebook folder)\n",
    "repo_root = Path().resolve().parent  # if notebook is in 'notebooks/' folder\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from config.config import get_environment\n",
    "\n",
    "from config.config import data_import_json, data_export_json, data_import_pandas, data_export_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5442f",
   "metadata": {},
   "source": [
    "## ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = get_environment(\n",
    "    env_path=\"../environments\",\n",
    "    env_name=\"env.json\"\n",
    ")\n",
    "\n",
    "# content_date = datetime.now().date() + timedelta(days=0)\n",
    "content_date = ENV['CONTENT_DATE']\n",
    "website = ENV['SOURCE']['NAME']\n",
    "version = ENV['VERSION']\n",
    "\n",
    "url_scrape = ENV['SOURCE']['URL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51fb22",
   "metadata": {},
   "source": [
    "## Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e01416",
   "metadata": {},
   "source": [
    "### Get Total Items Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43df6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_count = {\n",
    "    'accept': 'application/json, text/plain, */*',\n",
    "    'accept-language': 'en-US,en;q=0.9,id;q=0.8',\n",
    "    'adjust_device_id': '0de186d9-af6f-44cc-27c5-d0b78ebaec19',\n",
    "    'origin': 'https://www.sociolla.com',\n",
    "    'priority': 'u=1, i',\n",
    "    'referer': 'https://www.sociolla.com/',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"142\", \"Google Chrome\";v=\"142\", \"Not_A Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'session_id': 'slwrj5hc-iul1-4nuu-bsty-5vnqflqtmcf5',\n",
    "    'soc-platform': 'sociolla-web-mobile',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',\n",
    "    # 'cookie': 'sso_token=1b6df37b214caba6ac913e935d4e82f644ecfdb4; SOCIOLLA_UTM_DATA={}; SOCIOLLA_SESSION_ID=slwrj5hc-iul1-4nuu-bsty-5vnqflqtmcf5; _gid=GA1.2.1512964316.1764085677; _gcl_au=1.1.2118681921.1764085678; _fbp=fb.1.1764085684064.131487521762752714; _hjSession_1067100=eyJpZCI6IjM0ODRlODg1LTA0NTQtNGUyNi1hMTBlLTA3NmQ4NjhkNmEyZCIsImMiOjE3NjQwODU2ODQxNzMsInMiOjAsInIiOjAsInNiIjowLCJzciI6MCwic2UiOjAsImZzIjoxLCJzcCI6MX0=; _tt_enable_cookie=1; _ttp=01KAXV6P6S7RFD10XVYF4EB3H4_.tt.1; _hjSessionUser_1067100=eyJpZCI6ImFhODUxY2M1LTUzZjktNTc2Yy05YWNmLWM5MmQyNmJjNjk4ZiIsImNyZWF0ZWQiOjE3NjQwODU2ODQxNzEsImV4aXN0aW5nIjp0cnVlfQ==; ttcsid=1764085684456::wNOTNM-WZilRf-bNQlPi.1.1764085724342.0; ttcsid_C10ST5FMJ1JP7306D860=1764085684455::bHsnIh5Apg41LRMq9u5J.1.1764085724343.0; ttcsid_C7FU0AI0VTGLO2V4FJK0=1764085684457::LhOq5jGx-4rzao-I8Mfe.1.1764085724343.0; _gat=1; _dc_gtm_UA-57294171-1=1; _ga_363PMMDMHM=GS2.1.s1764085678$o1$g1$t1764086157$j57$l0$h0; _ga=GA1.1.744826987.1764085677',\n",
    "}\n",
    "\n",
    "url_scrape_count = 'https://catalog-api4.sociolla.com/search/count?limit=16&skip=0&sort=-best-seller&filter=%7B%22categories.id%22:%225d3d50276b24d01599516819%22%7D'\n",
    "\n",
    "print(f\"Get Total Items Count | URL: {url_scrape_count}\")\n",
    "\n",
    "response_count = requests.get(\n",
    "    url_scrape_count,\n",
    "    headers=headers_count,\n",
    ")\n",
    "\n",
    "print(f\"Response Total Items Count | URL: {url_scrape_count} | STATUS CODE: {response_count.status_code}\")\n",
    "\n",
    "try:\n",
    "    total_items = response_count.json()['data']\n",
    "    print(f\"Total Items: {total_items}\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788205c",
   "metadata": {},
   "source": [
    "### Get Category and Items per Category (Currently Skincare only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_cat = {\n",
    "    'accept': 'application/json, text/plain, */*',\n",
    "    'accept-language': 'en-US,en;q=0.9,id;q=0.8',\n",
    "    'adjust_device_id': '0de186d9-af6f-44cc-27c5-d0b78ebaec19',\n",
    "    'origin': 'https://www.sociolla.com',\n",
    "    'priority': 'u=1, i',\n",
    "    'referer': 'https://www.sociolla.com/',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"142\", \"Google Chrome\";v=\"142\", \"Not_A Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'session_id': 'ytvqy8vv-onte-22sd-1sas-9gt5o4i6gjui',\n",
    "    'soc-platform': 'sociolla-web-mobile',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',\n",
    "    # 'cookie': 'sso_token=1b6df37b214caba6ac913e935d4e82f644ecfdb4; _gid=GA1.2.1512964316.1764085677; _fbp=fb.1.1764085684064.131487521762752714; _tt_enable_cookie=1; _ttp=01KAXV6P6S7RFD10XVYF4EB3H4_.tt.1; _hjSessionUser_1067100=eyJpZCI6ImFhODUxY2M1LTUzZjktNTc2Yy05YWNmLWM5MmQyNmJjNjk4ZiIsImNyZWF0ZWQiOjE3NjQwODU2ODQxNzEsImV4aXN0aW5nIjp0cnVlfQ==; SOCIOLLA_UTM_DATA={}; _hjSession_1067100=eyJpZCI6IjZkYmY5ZGUxLTMwYzctNGVhZS05MTI1LThjMmYyNmZiN2E5MyIsImMiOjE3NjQxMzM0MTQwMDMsInMiOjAsInIiOjAsInNiIjowLCJzciI6MCwic2UiOjAsImZzIjowLCJzcCI6MH0=; SOCIOLLA_SESSION_ID=ytvqy8vv-onte-22sd-1sas-9gt5o4i6gjui; ttcsid=1764135926535::e_gk012KkFyNpX1LV82t.3.1764137333823.0; ttcsid_C10ST5FMJ1JP7306D860=1764135926536::6QcxrwJgH9eifzn95eX2.3.1764137333823.0; ttcsid_C7FU0AI0VTGLO2V4FJK0=1764135926536::xvA3WuZ503PmR63S0msb.3.1764137333823.0; _gcl_au=1.1.2118681921.1764085678; _gat=1; _dc_gtm_UA-57294171-1=1; _ga_363PMMDMHM=GS2.1.s1764135924$o3$g1$t1764137458$j60$l0$h0; _ga=GA1.1.744826987.1764085677',\n",
    "}\n",
    "\n",
    "url_scrape_cat = 'https://catalog-api5.sociolla.com/v3/categories/children?filter=%7B%22name%22:%22Shop+By+Departments%22,%22depth%22:3%7D&fields=name,my_sociolla_sql_id,link_rewrite,parents,slug,banner_for_sociolla,logo&skip=0&limit=30&sort=position'\n",
    "\n",
    "print(f\"Get Item Categories | URL: {url_scrape_cat}\")\n",
    "\n",
    "response_cat = requests.get(\n",
    "    url_scrape_cat,\n",
    "    headers=headers_cat,\n",
    ")\n",
    "\n",
    "print(f\"Response Item Categories | URL: {url_scrape_cat} | STATUS CODE: {response_cat.status_code}\")\n",
    "\n",
    "# Filter only Skincare\n",
    "try:\n",
    "    item_cat = [d for d in response_cat.json()['data']['children'] if d['name'] in ['Skincare']][0]\n",
    "    print(f\"Total Categories: {len(item_cat['children'])}\")\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n",
    "# Loop count and id dependencies for categories within Skincare\n",
    "cat_count_list = list()\n",
    "for index, cat in enumerate(item_cat['children']):\n",
    "\n",
    "    url_cat_count = f'https://catalog-api4.sociolla.com/search/count?limit=16&skip=0&sort=-best-seller&filter=%7B%22categories.id%22:%22{cat[\"_id\"]}%22%7D'\n",
    "\n",
    "    print(f\"Get Total Items Count {index+1}/{len(item_cat['children'])} | URL: {url_cat_count}\")\n",
    "\n",
    "    response_cat_count = requests.get(\n",
    "        url_cat_count,\n",
    "        headers=headers_count,\n",
    "    )\n",
    "\n",
    "    print(f\"Response Category Items Count {index+1}/{len(item_cat['children'])} | URL: {url_cat_count} | STATUS CODE: {response_cat_count.status_code}\")\n",
    "\n",
    "    cat_dict = dict()\n",
    "    try:\n",
    "        cat_count = response_cat_count.json()['data']\n",
    "        cat_dict['status_code'] = response_cat_count.status_code\n",
    "        cat_dict['id'] = cat['_id']\n",
    "        cat_dict['name'] = cat['name']\n",
    "        cat_dict['slug'] = cat['slug']\n",
    "        cat_dict['items_count'] = cat_count\n",
    "        cat_count_list.append(cat_dict)\n",
    "        print(f\"Total {cat['name']} {cat['slug']} Items {index+1}/{len(item_cat['children'])}: {cat_count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {cat['name']} {cat['slug']} Items {index+1}/{len(item_cat['children'])}: {e}\")\n",
    "        cat_dict['status_code'] = response_cat_count.status_code\n",
    "        cat_dict['id'] = cat['_id']\n",
    "        cat_dict['name'] = cat['name']\n",
    "        cat_dict['slug'] = cat['slug']\n",
    "        cat_dict['items_count'] = 0\n",
    "        cat_dict['error'] = e\n",
    "        cat_count_list.append(cat_dict)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Insert category_items to item_cat\n",
    "item_cat['category_items'] = cat_count_list\n",
    "\n",
    "# Dump to json\n",
    "data_export_json(\n",
    "    data=item_cat,\n",
    "    content_date=content_date,\n",
    "    website=website,\n",
    "    folder_name=f'scraper/{website}',\n",
    "    version=version,\n",
    "    additional_info=f\"scrape-cat_all\",\n",
    "    metadata={\n",
    "        \"status_code\": response_cat.status_code,\n",
    "        \"total_items\": total_items,\n",
    "        \"total_categories\": len(item_cat['children']),\n",
    "        \"url_count\": url_scrape_count,\n",
    "        \"url_categories\": url_scrape_cat\n",
    "    }\n",
    ")\n",
    "\n",
    "diff = abs(total_items - sum([i['items_count'] for i in item_cat['category_items']]))\n",
    "if diff > 20:\n",
    "    raise ValueError(\"Difference of Total Items vs Total Category Items more than 20:\", diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0334cb",
   "metadata": {},
   "source": [
    "### Scrape All Items on Skincare per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop all categories within Skincare\n",
    "from math import ceil\n",
    "\n",
    "for index, cat in enumerate(item_cat['category_items']):\n",
    "\n",
    "    cat_items = cat['items_count']\n",
    "    cat_name = cat['name']\n",
    "    cat_id = cat['id']\n",
    "    cat_slug = cat['slug']\n",
    "\n",
    "    # Generate looping count for each category\n",
    "    range_limit = 50 # default maximum limit per page\n",
    "    page_total = ceil(cat_items/range_limit)\n",
    "\n",
    "    print(f\"Category {cat_name} {cat_slug}: {index+1}/{len(item_cat['category_items'])} | Category Items: {cat_items} | Range Limit: {range_limit} | Loop Page: {page_total}\")\n",
    "\n",
    "    for loop_count in range(page_total):\n",
    "        page = loop_count+1\n",
    "        headers = {\n",
    "            'accept': 'application/json, text/plain, */*',\n",
    "            'accept-language': 'en-US,en;q=0.9,id;q=0.8',\n",
    "            'adjust_device_id': '0de186d9-af6f-44cc-27c5-d0b78ebaec19',\n",
    "            'origin': 'https://www.sociolla.com',\n",
    "            'priority': 'u=1, i',\n",
    "            'referer': 'https://www.sociolla.com/',\n",
    "            'sec-ch-ua': '\"Chromium\";v=\"142\", \"Google Chrome\";v=\"142\", \"Not_A Brand\";v=\"99\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"Windows\"',\n",
    "            'sec-fetch-dest': 'empty',\n",
    "            'sec-fetch-mode': 'cors',\n",
    "            'sec-fetch-site': 'same-site',\n",
    "            'session_id': 'slwrj5hc-iul1-4nuu-bsty-5vnqflqtmcf5',\n",
    "            'soc-platform': 'sociolla-web-mobile',\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',\n",
    "            # 'cookie': 'sso_token=1b6df37b214caba6ac913e935d4e82f644ecfdb4; SOCIOLLA_UTM_DATA={}; SOCIOLLA_SESSION_ID=slwrj5hc-iul1-4nuu-bsty-5vnqflqtmcf5; _gid=GA1.2.1512964316.1764085677; _gcl_au=1.1.2118681921.1764085678; _fbp=fb.1.1764085684064.131487521762752714; _hjSession_1067100=eyJpZCI6IjM0ODRlODg1LTA0NTQtNGUyNi1hMTBlLTA3NmQ4NjhkNmEyZCIsImMiOjE3NjQwODU2ODQxNzMsInMiOjAsInIiOjAsInNiIjowLCJzciI6MCwic2UiOjAsImZzIjoxLCJzcCI6MX0=; _tt_enable_cookie=1; _ttp=01KAXV6P6S7RFD10XVYF4EB3H4_.tt.1; _hjSessionUser_1067100=eyJpZCI6ImFhODUxY2M1LTUzZjktNTc2Yy05YWNmLWM5MmQyNmJjNjk4ZiIsImNyZWF0ZWQiOjE3NjQwODU2ODQxNzEsImV4aXN0aW5nIjp0cnVlfQ==; ttcsid=1764085684456::wNOTNM-WZilRf-bNQlPi.1.1764085724342.0; ttcsid_C10ST5FMJ1JP7306D860=1764085684455::bHsnIh5Apg41LRMq9u5J.1.1764085724343.0; ttcsid_C7FU0AI0VTGLO2V4FJK0=1764085684457::LhOq5jGx-4rzao-I8Mfe.1.1764085724343.0; _gat=1; _dc_gtm_UA-57294171-1=1; _ga_363PMMDMHM=GS2.1.s1764085678$o1$g1$t1764086157$j57$l0$h0; _ga=GA1.1.744826987.1764085677',\n",
    "        }\n",
    "\n",
    "        url_scrape = f'https://catalog-api.sociolla.com/search?limit={range_limit}&skip={range_limit*loop_count}&sort=-best-seller&filter=%7B%22categories.id%22:%22{cat_id}%22%7D'\n",
    "\n",
    "        print(f\"Get Category Items {cat_name} {cat_slug}: {index+1}/{len(item_cat['category_items'])} | Loop Page: {page}/{page_total} | URL: {url_scrape}\")\n",
    "\n",
    "        response = requests.get(\n",
    "            url_scrape,\n",
    "            headers=headers,\n",
    "        )\n",
    "\n",
    "        print(f\"Response Category Items {cat_name} {cat_slug}: {index+1}/{len(item_cat['category_items'])} | Loop Page: {page}/{page_total} | URL: {url_scrape} | STATUS CODE: {response.status_code}\")\n",
    "\n",
    "        try:\n",
    "            data_export_json(\n",
    "                data=response.json(),\n",
    "                website=website,\n",
    "                folder_name=f'scraper/{website}',\n",
    "                version=version,\n",
    "                content_date=content_date, # \"0000-00-00\"\n",
    "                additional_info=f\"scrape-cat_{cat_id}-page{page}\",\n",
    "                metadata={\n",
    "                    \"status_code\": response.status_code,\n",
    "                    \"cat_items\": cat_items,\n",
    "                    \"cat_name\": cat_name,\n",
    "                    \"cat_id\": cat_id,\n",
    "                    \"cat_slug\": cat_slug,\n",
    "                    \"page\": page,\n",
    "                    \"url_scrape\": url_scrape\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            data_export_json(\n",
    "                data=response.text,\n",
    "                website=website,\n",
    "                folder_name=f'scraper/{website}',\n",
    "                version=version,\n",
    "                content_date=content_date, # \"0000-00-00\"\n",
    "                additional_info=f\"scrape-cat_{cat_id}-page{page}\",\n",
    "                metadata={\n",
    "                    \"status_code\": response.status_code,\n",
    "                    \"error\": e,\n",
    "                    \"cat_items\": cat_items,\n",
    "                    \"cat_name\": cat_name,\n",
    "                    \"cat_id\": cat_id,\n",
    "                    \"cat_slug\": cat_slug,\n",
    "                    \"page\": page,\n",
    "                    \"url_scrape\": url_scrape\n",
    "                }\n",
    "            )\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499b99f",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493606c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_item_variant(\n",
    "        response_json: dict,\n",
    "        scrape_date: datetime,\n",
    "        cat_name: str,\n",
    "        cat_slug: str,\n",
    "        page_cat: int,\n",
    "        len_item_cat: int,\n",
    "        page: int,\n",
    "        page_total: int,\n",
    "        url_scrape: str\n",
    "    ):\n",
    "\n",
    "    len_item = len(response_json['data'])\n",
    "    parsed_list = list()\n",
    "    for index, items in enumerate(response_json['data']):\n",
    "        item_count = index+1\n",
    "\n",
    "        # Item Dependencies Across Variants\n",
    "        item_id = items['id']\n",
    "        item_brand = items['brand']['name']\n",
    "        item_name = items['name']\n",
    "        try:\n",
    "            item_url = items['url_sociolla']\n",
    "        except KeyError as e:\n",
    "            item_url = None\n",
    "        item_slug = items['slug']\n",
    "        # Item Ranking Dependencies\n",
    "        review_total = items['review_stats']['total_reviews']\n",
    "        review_rating = items['review_stats']['average_rating']\n",
    "        review_recommended = items['review_stats']['total_recommended_count']\n",
    "        try:\n",
    "            wishlist = items['total_wishlist']\n",
    "        except KeyError as e:\n",
    "            wishlist = None\n",
    "        price_range = items['price_range']\n",
    "\n",
    "        len_var = len(items['combinations'])\n",
    "\n",
    "        if len([v for v in items['combinations'] if 'attributes' in v.keys()]) > 0:\n",
    "            is_package = False\n",
    "            print(f\"Parsing Category Items {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Loop Page: {page}/{page_total} | Loop Item: {item_count}/{len_item} | Count Variant: {len_var} | Is Package: {is_package} | URL: {url_scrape}\")\n",
    "            for index, c in enumerate(items['combinations']):\n",
    "                if 'attributes' not in c.keys():\n",
    "                    continue\n",
    "                try:\n",
    "                    # for attr in c['attributes'].keys():\n",
    "                    try:\n",
    "                        variant_id = [c['attributes'][attr]['my_soco_sql_id'] for attr in c['attributes'].keys()]\n",
    "                    except KeyError:\n",
    "                        variant_id = None\n",
    "                    try:\n",
    "                        variant_name = [c['attributes'][attr]['name'] for attr in c['attributes'].keys()]\n",
    "                    except KeyError:\n",
    "                        variant_name = None\n",
    "                    if len(c['images']) > 0:\n",
    "                        try:\n",
    "                            url_image = [v['url'] for v in c['images'] if v['is_cover']][0]\n",
    "                        except Exception:\n",
    "                            try:\n",
    "                                url_image = [v['url'] for v in c['images'] if not v['is_cover']][0]\n",
    "                            except Exception:\n",
    "                                url_image = [v['url'] for v in items['images']][0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            url_image = [v['url'] for v in items['images']][0]\n",
    "                        except Exception:\n",
    "                            url_image = None \n",
    "\n",
    "                    data_dict = dict()\n",
    "                    data_dict['scrape_date'] = str(scrape_date)\n",
    "                    data_dict['category_slug'] = cat_slug\n",
    "                    data_dict['category'] = cat_name\n",
    "                    data_dict['slug'] = item_slug\n",
    "                    data_dict['id'] = item_id\n",
    "                    data_dict['brand'] = item_brand\n",
    "                    data_dict['name'] = item_name\n",
    "                    data_dict['url'] = item_url\n",
    "                    data_dict['url_image'] = url_image\n",
    "                    data_dict['review_total'] = review_total\n",
    "                    data_dict['review_rating'] = review_rating\n",
    "                    data_dict['review_recommended'] = review_recommended\n",
    "                    data_dict['wishlist'] = wishlist\n",
    "                    data_dict['variant_id'] = variant_id\n",
    "                    data_dict['variant_name'] = variant_name\n",
    "                    data_dict['stock'] = c['stock']\n",
    "                    data_dict['ean'] = c['ean_no']\n",
    "                    data_dict['currency'] = 'IDR'\n",
    "                    data_dict['price_range'] = price_range\n",
    "                    data_dict['price'] = c['price']\n",
    "                    data_dict['price_after_disc'] = c['price_after_discount']\n",
    "                    data_dict['price_disc_type'] = c['deduction_type']\n",
    "                    data_dict['price_disc'] = c['deduction_amount']\n",
    "                    data_dict['price_disc_perc'] = c['deduction_percentage']\n",
    "                    data_dict['is_package'] = is_package\n",
    "\n",
    "                    parsed_list.append(data_dict)\n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR Parsing Category Items {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Loop Page: {page}/{page_total} | Loop Item: {item_count}/{len_item} | Count Variant: {len_var} | Is Package: {is_package} | Variant Index: {index} | {e}\")\n",
    "                    continue\n",
    "\n",
    "        elif len(items['pack_detail']) > 0:\n",
    "            is_package = True\n",
    "            print(f\"Parsing Category Items {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Loop Page: {page}/{page_total} | Loop Item: {item_count}/{len_item} | Count Variant: {len_var} | Is Package: {is_package} | URL: {url_scrape}\")\n",
    "            try:\n",
    "                # for attr in items['default_combination']['attributes'].keys():\n",
    "                try:\n",
    "                    variant_id = [items['default_combination']['attributes'][attr]['my_soco_sql_id'] for attr in items['default_combination']['attributes'].keys()]\n",
    "                except KeyError:\n",
    "                    variant_id = None\n",
    "                try:\n",
    "                    variant_name = [items['default_combination']['attributes'][attr]['name'] for attr in items['default_combination']['attributes'].keys()]\n",
    "                except KeyError:\n",
    "                    variant_name = None\n",
    "                if len(items['default_combination']['images']) > 0:\n",
    "                    try:\n",
    "                        url_image = [v['url'] for v in items['default_combination']['images'] if v['is_cover']][0]\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            url_image = [v['url'] for v in items['default_combination']['images'] if not v['is_cover']][0]\n",
    "                        except Exception:\n",
    "                            url_image = [v['url'] for v in items['images']][0]\n",
    "                else:\n",
    "                    try:\n",
    "                        url_image = [v['url'] for v in items['images']][0]\n",
    "                    except Exception:\n",
    "                        url_image = None \n",
    "\n",
    "                data_dict = dict()\n",
    "                data_dict['scrape_date'] = str(scrape_date)\n",
    "                data_dict['category_slug'] = cat_slug\n",
    "                data_dict['category'] = cat_name\n",
    "                data_dict['slug'] = item_slug\n",
    "                data_dict['id'] = item_id\n",
    "                data_dict['brand'] = item_brand\n",
    "                data_dict['name'] = item_name\n",
    "                data_dict['url'] = item_url\n",
    "                data_dict['url_image'] = url_image\n",
    "                data_dict['review_total'] = review_total\n",
    "                data_dict['review_rating'] = review_rating\n",
    "                data_dict['review_recommended'] = review_recommended\n",
    "                data_dict['wishlist'] = wishlist\n",
    "                data_dict['variant_id'] = variant_id\n",
    "                data_dict['variant_name'] = variant_name\n",
    "                data_dict['stock'] = items['default_combination']['stock']\n",
    "                data_dict['ean'] = None\n",
    "                data_dict['currency'] = 'IDR'\n",
    "                data_dict['price_range'] = price_range\n",
    "                data_dict['price'] = items['default_combination']['price']\n",
    "                data_dict['price_after_disc'] = items['default_combination']['price_after_discount']\n",
    "                data_dict['price_disc_type'] = items['default_combination']['deduction_type']\n",
    "                data_dict['price_disc'] = items['default_combination']['deduction_amount']\n",
    "                data_dict['price_disc_perc'] = items['default_combination']['deduction_percentage']\n",
    "                data_dict['is_package'] = is_package\n",
    "\n",
    "                parsed_list.append(data_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR Parsing Category Items {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Loop Page: {page}/{page_total} | Loop Item: {item_count}/{len_item} | Count Variant: {len_var} | Is Package: {is_package} | {e}\")\n",
    "\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    return parsed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17684701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Item Cat Skincare\n",
    "item_cat = data_import_json(\n",
    "    content_date=content_date,\n",
    "    website=website,\n",
    "    folder_name=f'scraper/{website}',\n",
    "    version=version,\n",
    "    additional_info=f\"scrape-cat_all\"\n",
    ")\n",
    "item_cat = item_cat['data']\n",
    "\n",
    "len_item_cat = len(item_cat['category_items'])\n",
    "\n",
    "# Loop all categories within Skincare\n",
    "from math import ceil\n",
    "\n",
    "parsed_list = list()\n",
    "try:\n",
    "    for index, cat in enumerate(item_cat['category_items']):\n",
    "        page_cat = index+1\n",
    "        cat_items = cat['items_count']\n",
    "        cat_name = cat['name']\n",
    "        cat_id = cat['id']\n",
    "        cat_slug = cat['slug']\n",
    "\n",
    "        # Generate looping count for each category\n",
    "        range_limit = 50 # default maximum limit per page\n",
    "        page_total = ceil(cat_items/range_limit)\n",
    "\n",
    "        print(f\"Category {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Category Items: {cat_items} | Range Limit: {range_limit} | Page Total: {page_total}\")\n",
    "\n",
    "        for loop_count in range(page_total):\n",
    "            page = loop_count+1\n",
    "            url_scrape = f'https://catalog-api.sociolla.com/search?limit={range_limit}&skip={range_limit*loop_count}&sort=-best-seller&filter=%7B%22categories.id%22:%22{cat_id}%22%7D'\n",
    "\n",
    "            try:\n",
    "                response_json = data_import_json(\n",
    "                    website=website,\n",
    "                    folder_name=f'scraper/{website}',\n",
    "                    version=version,\n",
    "                    content_date=content_date, # \"0000-00-00\"\n",
    "                    additional_info=f\"scrape-cat_{cat_id}-page{page}\"\n",
    "                )\n",
    "                response_json = response_json['data']\n",
    "\n",
    "                # len_item = len(response_json['data'])\n",
    "                # parsed_list = list()\n",
    "                # for index, i in enumerate(response_json['data']):\n",
    "                #     item_count = index+1\n",
    "\n",
    "                parsed_list_temp = parser_item_variant(\n",
    "                    response_json=response_json,\n",
    "                    scrape_date=content_date,\n",
    "                    cat_name=cat_name,\n",
    "                    cat_slug=cat_slug,\n",
    "                    page_cat=page_cat,\n",
    "                    len_item_cat=len_item_cat,\n",
    "                    page=page,\n",
    "                    page_total=page_total,\n",
    "                    url_scrape=url_scrape\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                parsed_list_temp = list()\n",
    "                print(f\"ERROR Category Items {cat_name} {cat_slug}: {page_cat}/{len_item_cat} | Loop Page: {page}/{page_total} | URL: {url_scrape} | {e}\")\n",
    "                continue\n",
    "\n",
    "            parsed_list = parsed_list + parsed_list_temp\n",
    "\n",
    "    # Convert all list to DataFrame\n",
    "    df_parse = pd.DataFrame(parsed_list)\n",
    "\n",
    "    data_export_pandas(\n",
    "        df_output=df_parse,\n",
    "        website=website,\n",
    "        folder_name=f'parser/{website}',\n",
    "        version=version,\n",
    "        content_date=content_date, # \"0000-00-00\"\n",
    "        additional_info=\"parsed\",\n",
    "        incl_excel=True\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    df_parse = pd.DataFrame(parsed_list)\n",
    "    data_export_pandas(\n",
    "        df_output=df_parse,\n",
    "        website=website,\n",
    "        folder_name=f'parser/{website}',\n",
    "        version=version,\n",
    "        content_date=content_date, # \"0000-00-00\"\n",
    "        additional_info=\"parsed\",\n",
    "        incl_excel=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
